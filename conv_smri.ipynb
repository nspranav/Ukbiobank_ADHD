{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.core.numeric import indices\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from custom_dataset import CustomDataset\n",
    "from network import Network\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################\n",
    "# Loading the Data #####\n",
    "########################\n",
    "\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 4\n",
    "# how many samples per batch to load\n",
    "batch_size = 30\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.1\n",
    "# percentage of data to be used for testset\n",
    "test_size = 0.05\n",
    "\n",
    "\n",
    "data = CustomDataset(transform = \n",
    "                        transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "# obtaining indices that will be used for train, validation, and test\n",
    "\n",
    "num_train = len(data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "test_split = int(np.floor(test_size * num_train))\n",
    "test_idx, train_idx = indices[: test_split], indices[test_split : ]\n",
    "\n",
    "train_rem = len(train_idx)\n",
    "valid_spilt = int(np.floor(valid_size * train_rem))\n",
    "\n",
    "valid_idx, train_idx = indices[: valid_spilt], indices[valid_spilt : ]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = DataLoader(data,batch_size=batch_size, \n",
    "                            sampler= train_sampler, num_workers=num_workers)\n",
    "valid_loader = DataLoader(data,batch_size=batch_size, \n",
    "                            sampler= valid_sampler, num_workers=num_workers)\n",
    "test_loader = DataLoader(data,batch_size = batch_size, \n",
    "                            sampler = test_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10..  Training Loss: 2.371..  Test Loss: 2.435.. \n",
      "Epoch: 2/10..  Training Loss: 2.257..  Test Loss: 2.284.. \n",
      "Epoch: 3/10..  Training Loss: 2.240..  Test Loss: 2.247.. \n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.03,weight_decay=0.001)\n",
    "\n",
    "epochs = 10\n",
    "train_losses, validation_losses = [],[]\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    train_loss = 0\n",
    "    for imgs,labels in train_loader:\n",
    "\n",
    "        if train_on_gpu:\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(torch.unsqueeze(imgs,1).float())\n",
    "\n",
    "        loss = criterion(output,torch.unsqueeze(labels,1))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "        validation_loss = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for imgs,labels in valid_loader:\n",
    "                if train_on_gpu:\n",
    "                    imgs = imgs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                \n",
    "                pred = model(torch.unsqueeze(imgs,1).float())\n",
    "\n",
    "                loss = criterion(pred,torch.unsqueeze(labels,1))\n",
    "\n",
    "                validation_loss += loss.item()\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "            train_losses.append(train_loss/len(train_loader))\n",
    "            validation_losses.append(validation_loss/len(valid_loader))\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "              \"Test Loss: {:.3f}.. \".format(validation_losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('CV2': conda)",
   "name": "cv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}