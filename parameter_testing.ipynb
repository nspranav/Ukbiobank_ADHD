{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from custom_dataset import CustomDataset\n",
    "from network import Network\n",
    "from utils import *\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "parent_directory = '/data/users2/pnadigapusuresh1/JobOutputs'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model for 1 Fully-connected layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Network()\n",
    "#model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# Loading the model from Job 5436878\n",
    "#loading model from 6066159\n",
    "load_path = os.path.join(parent_directory,'5436878','models','epoch_28')\n",
    "\n",
    "model.load_state_dict(torch.load(load_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(52)\n",
    "np.random.seed(52)\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 1\n",
    "# how many samples per batch to load\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 0.20\n",
    "# percentage of data to be used for testset\n",
    "test_size = 0.10\n",
    "\n",
    "\n",
    "train_data = CustomDataset(transform = \n",
    "                        transforms.Compose([\n",
    "                            transforms.RandomHorizontalFlip()\n",
    "                            ]),train=True)\n",
    "\n",
    "valid_data = CustomDataset(train=False)\n",
    "\n",
    "# get filtered variables\n",
    "vars = valid_data.vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "test_split = int(np.floor(test_size * num_train))\n",
    "test_idx, train_idx = indices[: test_split], indices[test_split : ]\n",
    "\n",
    "train_rem = len(train_idx)\n",
    "valid_spilt = int(np.floor(valid_size * train_rem))\n",
    "\n",
    "valid_idx, train_idx = indices[: valid_spilt], indices[valid_spilt : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "test_loader = DataLoader(valid_data,batch_size = batch_size, \n",
    "                            sampler = test_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    actual_test = torch.tensor([]).to(device)\n",
    "    pred_test = torch.tensor([]).to(device)\n",
    "\n",
    "    test_loss = 0\n",
    "\n",
    "    for X, y in test_loader:\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        actual_test = torch.cat((actual_test,y),0)\n",
    "        pred = torch.squeeze(model(torch.unsqueeze(X,1).float()))\n",
    "        try:\n",
    "            test_loss += criterion(pred,y.float()).item()\n",
    "        except:\n",
    "            print(pred)\n",
    "            print(y)\n",
    "    \n",
    "    return test_loss/len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Fc Layer/Folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for 1 FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean = 2.9498000000000006\n",
      "train std = 0.04677349676900367\n",
      "val mean = 2.999\n",
      "val std = 0.0533778980477876\n"
     ]
    }
   ],
   "source": [
    "train_scores = [3.014,2.927,2.990,2.935,2.883]\n",
    "val_scores = [2.960,3.033,3.071,2.920,3.011]\n",
    "\n",
    "print('train mean =',np.mean(train_scores))\n",
    "print('train std =',np.std(train_scores))\n",
    "print('val mean =',np.mean(val_scores))\n",
    "print('val std =',np.std(val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model.fc1 = nn.Sequential(nn.Linear(512,1))\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_1fc = {\n",
    "    '1' : 'epoch_65',\n",
    "    '2' : 'epoch_71',\n",
    "    '3' : 'epoch_65',\n",
    "    '4' : 'epoch_71',\n",
    "    '5' : 'epoch_75'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  3.274067613364391\n",
      "std =  0.21072294520415621\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for k,v in best_models_1fc.items():\n",
    "    load_path = os.path.join(parent_directory,'6164265/models_fold',k,v)\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "    test_scores.append(test(model))\n",
    "\n",
    "print('mean = ',np.mean(test_scores))\n",
    "print('std = ',np.std(test_scores)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for 2 Fc layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean = 4.6938\n",
      "train std = 0.24044741628888447\n",
      "val mean = 4.6156\n",
      "val std = 0.1901016570153978\n"
     ]
    }
   ],
   "source": [
    "train_scores = [4.956, 4.413, 4.980, 4.451, 4.669]\n",
    "val_scores = [4.854, 4.495, 4.834, 4.397, 4.498]\n",
    "\n",
    "print('train mean =',np.mean(train_scores))\n",
    "print('train std =',np.std(train_scores))\n",
    "print('val mean =',np.mean(val_scores))\n",
    "print('val std =',np.std(val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Network(\n",
       "    (cv1): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (cv2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (cv3): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (bn3): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (cv4): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (bn4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (cv5): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (bn5): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (fc1): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "    (d3d): Dropout3d(p=0.2, inplace=False)\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (convs): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model.fc1 = nn.Sequential(nn.Linear(512,256),nn.ReLU(),\n",
    "    nn.Dropout(),nn.Linear(256,1))\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_2fc = {\n",
    "    '1' : 'epoch_26',\n",
    "    '2' : 'epoch_74',\n",
    "    '3' : 'epoch_25',\n",
    "    '4' : 'epoch_66',\n",
    "    '5' : 'epoch_48'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  5.720739652510709\n",
      "std =  0.8713915309932332\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for k,v in best_models_2fc.items():\n",
    "    load_path = os.path.join(parent_directory,'6173079/models_fold',k,v)\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "    test_scores.append(test(model))\n",
    "\n",
    "print('mean = ',np.mean(test_scores))\n",
    "print('std = ',np.std(test_scores)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for 3 Fc layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean = 6.4706\n",
      "train std = 0.4304809403446335\n",
      "val mean = 6.837200000000001\n",
      "val std = 1.0286755367947655\n"
     ]
    }
   ],
   "source": [
    "train_scores = [7.314, 6.267, 6.291, 6.107, 6.374]\n",
    "val_scores = [8.838, 6.731, 6.394, 5.996, 6.227]\n",
    "\n",
    "print('train mean =',np.mean(train_scores))\n",
    "print('train std =',np.std(train_scores))\n",
    "print('val mean =',np.mean(val_scores))\n",
    "print('val std =',np.std(val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Network(\n",
       "    (cv1): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (cv2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (cv3): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (bn3): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (cv4): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (bn4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (cv5): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (bn5): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (fc1): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "    (d3d): Dropout3d(p=0.2, inplace=False)\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (convs): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model.fc1 = nn.Sequential(nn.Linear(512,256),nn.ReLU(),\n",
    "    nn.Dropout(),nn.Linear(256,128),nn.ReLU(),nn.Dropout(),\n",
    "    nn.Linear(128,1))\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_3fc = {\n",
    "    '3' : 'epoch_62',\n",
    "    '4' : 'epoch_75',\n",
    "    '5' : 'epoch_51'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  7.953095125702192\n",
      "std =  0.3487180256342292\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for k,v in best_models_3fc.items():\n",
    "    load_path = os.path.join(parent_directory,'6183834/models_fold',k,v)\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "    test_scores.append(test(model))\n",
    "\n",
    "print('mean = ',np.mean(test_scores))\n",
    "print('std = ',np.std(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b101a7ee825fcd2f5a7c1becefa556e413ac576d4847d7d0423e65831f79e9ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
