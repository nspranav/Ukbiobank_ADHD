{"cells":[{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import json\n","from captum.attr import IntegratedGradients,Occlusion\n","from nilearn.image import load_img,resample_img \n","\n","import torch\n","from torch import nn \n","from torch.utils.data import DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","from custom_dataset import CustomDataset\n","from network import Network\n","from utils import *\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n"]}],"source":["parent_directory = '/data/users2/pnadigapusuresh1/JobOutputs'\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using {} device\".format(device))\n","\n","model = Network()\n","model.fc1 = nn.Sequential(nn.Linear(512,2))\n","model = nn.DataParallel(model)\n","model.to(device)\n","\n","# Loading the model from Job 5436878\n","#loading model from 6066159\n","#load_path = os.path.join(parent_directory,'6066159','models','epoch_170')\n","\n","#loading model from 1780660\n","load_path = os.path.join(parent_directory,'1818979','models_fold','5','epoch_38')\n","model.load_state_dict(torch.load(load_path))\n","model.eval()\n","\n","torch.manual_seed(52)\n","np.random.seed(52)\n","# number of subprocesses to use for data loading\n","num_workers = 1\n","# how many samples per batch to load\n","batch_size = 1\n","\n","valid_data = CustomDataset(train= False,valid=False)\n","\n","# get filtered variables\n","vars = valid_data.vars.iloc[valid_data.test_idx]\n","\n","valid_sampler = SubsetRandomSampler(valid_data.female_idx)\n","\n","valid_loader = DataLoader(valid_data,batch_size=batch_size, \n","                            sampler= valid_sampler, num_workers=num_workers)\n","\n","X_all = np.zeros((121,145,121))\n","for X,y,age in valid_loader:\n","    X_all = np.add(X_all , X.squeeze())\n","X_all /= len(valid_loader)\n","X_all = np.expand_dims(np.expand_dims(X_all,axis =0),axis=0)\n","X_all = torch.tensor(X_all).float().to(device)\n","\n","ig = Occlusion(model)\n","\n","attr_0 = attr_1 = np.zeros((121,145,121),dtype = np.float64)\n","\n","with open('region_labels.json','r') as f:\n","    l = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["imf = load_img('/trdapps/linux-x86_64/matlab/toolboxes/spm12/tpm/labels_Neuromorphometrics.nii')\n","aal = load_img('/data/users2/pnadigapusuresh1/Downloads/AAL3/AAL3v1.nii.gz')\n","aal_resampled = resample_img('/data/users2/pnadigapusuresh1/Downloads/AAL3/aal.nii.gz',target_affine=imf.affine,target_shape=imf.shape).get_fdata()\n","df = pd.read_csv('/data/users2/pnadigapusuresh1/Downloads/AAL3/aal.nii.txt',sep=' ',index_col=0,header=None,usecols=[0,1],names=['value','regions'])\n","l = df.to_dict()['regions']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["labels = {v:0 for k,v in l.items()}\n","labels['age'] = 0\n","relevance_scores = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for X,y,age in valid_loader:\n","    X,y = X.to(device),y.to(device)\n","    pred = torch.squeeze(model(torch.unsqueeze(X,1).float()))\n","    soft_max = F.softmax(pred,dim=0)\n","    if soft_max.argmax() != y:\n","        continue\n","    unoccluded_prob = soft_max[y].data\n","    # compute occlusion\n","    labels_copy = labels.copy()\n","    for k,v in l.items():\n","        # occlude image\n","        X_copy = X.clone().squeeze()\n","        X_copy[aal_resampled == k] = 0\n","        X_copy = torch.unsqueeze(X_copy,0)\n","        pred = torch.squeeze(model(torch.unsqueeze(X_copy,1).float()))\n","        soft_max = F.softmax(pred,dim=0)\n","        occluded_prob = soft_max[y].data\n","        labels_copy[l[k]] = (unoccluded_prob - occluded_prob).detach().cpu().numpy()[0]\n","    else:\n","        labels_copy['age'] = age.item()\n","        labels_copy['memory'] = y.item()\n","        relevance_scores.append(labels_copy)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["female_df_occlusion = pd.DataFrame.from_dict(relevance_scores)\n","female_df_occlusion.to_csv('female_df_occ_wrong.csv',',')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"latest","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"65354879b211816c06816317081346b51d26a7261dd303864e7df7aa3071e8ab"}}},"nbformat":4,"nbformat_minor":2}
